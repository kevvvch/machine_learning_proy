{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines\n",
    "#=================================================#\n",
    "IS_TRAIN_NOT_TEST = True\n",
    "\n",
    "ENV_LOCAL_MACHINE   = 1\n",
    "ENV_GOOGLE_COLLABS  = 2\n",
    "ENV_KAGGLE          = 3\n",
    "ENVIRONMENT = ENV_LOCAL_MACHINE\n",
    "\n",
    "#================================== =======s========#\n",
    "CSV_DATASET_INPUT   = \"dataset_train.csv\"\n",
    "CSV_DATASET_OUTPUT  = \"dataset_transformed.csv\"\n",
    "\n",
    "if ENVIRONMENT == ENV_LOCAL_MACHINE:\n",
    "    PATH_DATASET_INPUT  = \"./dataset_raw/\"\n",
    "    PATH_DATASET_OUTPUT = \"./outputs/\"\n",
    "if ENVIRONMENT == ENV_GOOGLE_COLLABS:\n",
    "    PATH_DATASET_INPUT  = \"drive/MyDrive/UTN_Finales/[F] Aprendizaje Automatico/Repositorio/dataset_raw/\"\n",
    "    PATH_DATASET_OUTPUT = \"drive/MyDrive/UTN_Finales/[F] Aprendizaje Automatico/Repositorio/outputs/\"\n",
    "\n",
    "FEATURE_TARGET = \"is_click\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENVIRONMENT != ENV_LOCAL_MACHINE:\n",
    "    !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "if ENVIRONMENT == ENV_GOOGLE_COLLABS:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "dataset = pd.read_csv(PATH_DATASET_INPUT+CSV_DATASET_INPUT)\n",
    "dataset_size = dataset.size\n",
    "\n",
    "# Convert object columns to string\n",
    "for col in dataset.select_dtypes(include=['object']).columns:\n",
    "    dataset[col] = dataset[col].astype(\"string\")\n",
    "\n",
    "dataset_t = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def remove_feature(ds, feature):\n",
    "    return ds.drop([feature], axis=1)\n",
    "\n",
    "def fill_na(ds, feature, filler):\n",
    "    return ds[feature].fillna(filler)\n",
    "\n",
    "def encode_frequencyEncoding(ds, feature):\n",
    "    frequency_encoding = ds[feature].value_counts() / len(dataset_t)\n",
    "    return ds[feature].map(frequency_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns which represent too many missing values\n",
    "dataset_t = remove_feature(dataset_t, \"product_category_2\")\n",
    "\n",
    "# Remove random parameters\n",
    "dataset_t = remove_feature(dataset_t, \"session_id\")\n",
    "dataset_t = remove_feature(dataset_t, \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dateTime column into minutes column\n",
    "dataset_t[\"DateTime\"] = pd.to_datetime(dataset_t[\"DateTime\"])\n",
    "dataset_t[\"minutes\"] = dataset_t[\"DateTime\"].dt.hour * 60 + dataset_t[\"DateTime\"].dt.minute\n",
    "\n",
    "# Apply sine and cosine transformations\n",
    "period = 60*24\n",
    "dataset_t[\"minutes_sin\"] = np.sin(2 * np.pi * dataset_t[\"minutes\"] / period)\n",
    "dataset_t[\"minutes_cos\"] = np.cos(2 * np.pi * dataset_t[\"minutes\"] / period)\n",
    "\n",
    "# Remove datetime and minutes column\n",
    "dataset_t = remove_feature(dataset_t, \"DateTime\")\n",
    "dataset_t = remove_feature(dataset_t, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill not specified gender with string \"Not Specified\"\n",
    "dataset_t[\"gender\"] = fill_na(dataset_t, \"gender\", \"Not Specified\")\n",
    "dataset_t[\"is_male\"]    = dataset_t[\"gender\"].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "dataset_t[\"is_female\"]  = dataset_t[\"gender\"].apply(lambda x: 1 if x == 'Female' else 0)\n",
    "\n",
    "# Remove gender column\n",
    "dataset_t = remove_feature(dataset_t, \"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding\n",
    "dataset_t['webpage_id_encoded'] = encode_frequencyEncoding(dataset_t, \"webpage_id\")\n",
    "\n",
    "# Remove webpage_id column\n",
    "dataset_t = remove_feature(dataset_t, \"webpage_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding\n",
    "dataset_t['campaign_id_encoded'] = encode_frequencyEncoding(dataset_t, \"campaign_id\")\n",
    "\n",
    "# Remove campaign_id column\n",
    "dataset_t = remove_feature(dataset_t, \"campaign_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "d:\\Program Files\\Python\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "d:\\Program Files\\Python\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Fill with 0.0\n",
    "dataset_t[\"user_group_id\"] = fill_na(dataset_t, \"user_group_id\", 0.0)\n",
    "\n",
    "# Binary encoding\n",
    "encoder = ce.BinaryEncoder(cols=['user_group_id'])\n",
    "df_encoded = encoder.fit_transform(dataset_t['user_group_id'])\n",
    "dataset_t = pd.concat([df_encoded, dataset_t], axis=1)\n",
    "\n",
    "# Remove user_group_id column\n",
    "dataset_t = remove_feature(dataset_t, \"user_group_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding\n",
    "encoder = ce.BinaryEncoder(cols=['product'])\n",
    "df_encoded = encoder.fit_transform(dataset_t['product'])\n",
    "dataset_t = pd.concat([df_encoded, dataset_t], axis=1)\n",
    "\n",
    "# Remove product column\n",
    "dataset_t = remove_feature(dataset_t, \"product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with most frequent value\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "dataset_t['age_level'] = mode_imputer.fit_transform(dataset_t[[\"age_level\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with 1.0\n",
    "dataset_t[\"user_depth\"] = fill_na(dataset_t, \"user_depth\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with most frequent value\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "dataset_t['city_development_index'] = mode_imputer.fit_transform(dataset_t[[\"city_development_index\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0  1\n",
      "product_0               0.0  0\n",
      "product_1               0.0  0\n",
      "product_2               0.0  0\n",
      "product_3               0.0  0\n",
      "user_group_id_0         0.0  0\n",
      "user_group_id_1         0.0  0\n",
      "user_group_id_2         0.0  0\n",
      "user_group_id_3         0.0  0\n",
      "product_category_1      0.0  0\n",
      "age_level               0.0  0\n",
      "user_depth              0.0  0\n",
      "city_development_index  0.0  0\n",
      "var_1                   0.0  0\n",
      "is_click                0.0  0\n",
      "minutes_sin             0.0  0\n",
      "minutes_cos             0.0  0\n",
      "is_male                 0.0  0\n",
      "is_female               0.0  0\n",
      "webpage_id_encoded      0.0  0\n",
      "campaign_id_encoded     0.0  0\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(pd.concat([dataset_t.isna().sum()/dataset_size*100, dataset_t.isna().sum()], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_TRAIN_NOT_TEST == True:\n",
    "    # Append the column to move at the end of the list\n",
    "    cols = list(dataset_t.columns)\n",
    "    cols.remove(FEATURE_TARGET)\n",
    "    cols.append(FEATURE_TARGET)\n",
    "\n",
    "    dataset_t = dataset_t[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "dataset_t.to_csv(PATH_DATASET_OUTPUT+CSV_DATASET_OUTPUT, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
